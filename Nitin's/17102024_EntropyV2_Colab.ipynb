{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3d0f602cfb149ca9371e8da05f0b575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5200eab96ba4bc1abbee8fc8fe6e41a",
              "IPY_MODEL_97a26df8bbc9493bad5493434ad95fc1",
              "IPY_MODEL_463ea8267dc248a388d10bff53ef6091"
            ],
            "layout": "IPY_MODEL_3d2813acacd945338454b0ce7413eb66"
          }
        },
        "d5200eab96ba4bc1abbee8fc8fe6e41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c98616c2024eef8fc525c59eae52d2",
            "placeholder": "​",
            "style": "IPY_MODEL_d9658b6cc4984f80ab87e6dbf6a58ba7",
            "value": "config.json: 100%"
          }
        },
        "97a26df8bbc9493bad5493434ad95fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c1fdafaa9b48929a2089850ecabbd8",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adb3930a53fa4e1094f391e7e120c419",
            "value": 665
          }
        },
        "463ea8267dc248a388d10bff53ef6091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779086cd725b47f88b3c7f093aa018eb",
            "placeholder": "​",
            "style": "IPY_MODEL_285e9e86ddfd467cb75b2d5da1ae0939",
            "value": " 665/665 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "3d2813acacd945338454b0ce7413eb66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c98616c2024eef8fc525c59eae52d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9658b6cc4984f80ab87e6dbf6a58ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c1fdafaa9b48929a2089850ecabbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb3930a53fa4e1094f391e7e120c419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "779086cd725b47f88b3c7f093aa018eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285e9e86ddfd467cb75b2d5da1ae0939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d05da51637e947778763cb090f12f5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3e62fc151b9407bb16242978444000f",
              "IPY_MODEL_a7a3bc0e8f1044d9b623ab57d6c3d540",
              "IPY_MODEL_39a645621f724678ae21f6ca50dd672a"
            ],
            "layout": "IPY_MODEL_de0fb162ddad4f6a97510aba566e396a"
          }
        },
        "b3e62fc151b9407bb16242978444000f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2f5d3682b14fb78775b886348e55ac",
            "placeholder": "​",
            "style": "IPY_MODEL_fd7eacd3397942fe9993822b132b0b9f",
            "value": "model.safetensors: 100%"
          }
        },
        "a7a3bc0e8f1044d9b623ab57d6c3d540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdf5e35b6154746bee61bef8ada54b8",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6576c136152949ddae069012c9d036a4",
            "value": 548105171
          }
        },
        "39a645621f724678ae21f6ca50dd672a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9006243d0be453287cc868a4d328a62",
            "placeholder": "​",
            "style": "IPY_MODEL_2421b4256d2f44be8cf84a2a2a9a72e6",
            "value": " 548M/548M [00:05&lt;00:00, 161MB/s]"
          }
        },
        "de0fb162ddad4f6a97510aba566e396a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2f5d3682b14fb78775b886348e55ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7eacd3397942fe9993822b132b0b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfdf5e35b6154746bee61bef8ada54b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6576c136152949ddae069012c9d036a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9006243d0be453287cc868a4d328a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2421b4256d2f44be8cf84a2a2a9a72e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b3f3c528f14a1fba59e9f56f90abd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c18420c62414f74aecf68f6eb62300a",
              "IPY_MODEL_d25960d2cc4740a18b1571cf4d024d15",
              "IPY_MODEL_8827e0677a6b4705b5552ff72e972e48"
            ],
            "layout": "IPY_MODEL_62735853e974416d9bb2a03e5e51450c"
          }
        },
        "2c18420c62414f74aecf68f6eb62300a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930c7a1ede1d43518fe4547ae87c3078",
            "placeholder": "​",
            "style": "IPY_MODEL_966fb7a7a79e435ab489d17865532089",
            "value": "generation_config.json: 100%"
          }
        },
        "d25960d2cc4740a18b1571cf4d024d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84eb662fecce489886127f702d5f6797",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_324d0e84441a4d8189b6bbaf42162bc9",
            "value": 124
          }
        },
        "8827e0677a6b4705b5552ff72e972e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a517b4e23c694d0381bfc5e840f46f2e",
            "placeholder": "​",
            "style": "IPY_MODEL_e041277b88b7460da6d28e98e88b3c30",
            "value": " 124/124 [00:00&lt;00:00, 8.75kB/s]"
          }
        },
        "62735853e974416d9bb2a03e5e51450c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930c7a1ede1d43518fe4547ae87c3078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966fb7a7a79e435ab489d17865532089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84eb662fecce489886127f702d5f6797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324d0e84441a4d8189b6bbaf42162bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a517b4e23c694d0381bfc5e840f46f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e041277b88b7460da6d28e98e88b3c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86fca984b5aa4f7ea77779a213d217fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d089679d42d4065afd9239bf6d0fc93",
              "IPY_MODEL_34d834ed555d4426a19821f233a4568f",
              "IPY_MODEL_e669169671cf49c88c8984c043fca802"
            ],
            "layout": "IPY_MODEL_3b344ae6a1d84f0abffc91d15f20a160"
          }
        },
        "7d089679d42d4065afd9239bf6d0fc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef39fcb95bf453c902be5f4a27b0149",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e6f05a980749fcaf6afcbcadd4825a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "34d834ed555d4426a19821f233a4568f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1596f02aa24c3bb2e6a5fb9443a159",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d81104bf744403c90ad4afd405683a9",
            "value": 26
          }
        },
        "e669169671cf49c88c8984c043fca802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aadad6980664f10830730ae2c9dd5ff",
            "placeholder": "​",
            "style": "IPY_MODEL_031bab7d8a394481b8dfbb4413ec5ab6",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.92kB/s]"
          }
        },
        "3b344ae6a1d84f0abffc91d15f20a160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef39fcb95bf453c902be5f4a27b0149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e6f05a980749fcaf6afcbcadd4825a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c1596f02aa24c3bb2e6a5fb9443a159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d81104bf744403c90ad4afd405683a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aadad6980664f10830730ae2c9dd5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031bab7d8a394481b8dfbb4413ec5ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b5b375faba742f788e00d7ce47babda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e098f5b42b84cb98cc87fb0d566aa4c",
              "IPY_MODEL_4bf624f2b2cf4d73be47ca254c2541f5",
              "IPY_MODEL_4667a244280e4623bb878c86c61be2d0"
            ],
            "layout": "IPY_MODEL_5fb22f3ee16b4bd1b85f0753fd9c0546"
          }
        },
        "2e098f5b42b84cb98cc87fb0d566aa4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d04158c6aed40c28b106c80dfed8cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_15336168581a4bdb99b066f9186aee71",
            "value": "vocab.json: 100%"
          }
        },
        "4bf624f2b2cf4d73be47ca254c2541f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb51332c174405289decaac73961ec5",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7be4c3bc62347b3ab19a82bdd4cf34f",
            "value": 1042301
          }
        },
        "4667a244280e4623bb878c86c61be2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb4e388837f49bb964b9b2dc6321357",
            "placeholder": "​",
            "style": "IPY_MODEL_dffd8b755824412faf16bcf471eacfb2",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.28MB/s]"
          }
        },
        "5fb22f3ee16b4bd1b85f0753fd9c0546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d04158c6aed40c28b106c80dfed8cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15336168581a4bdb99b066f9186aee71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb51332c174405289decaac73961ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7be4c3bc62347b3ab19a82bdd4cf34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acb4e388837f49bb964b9b2dc6321357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dffd8b755824412faf16bcf471eacfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f471af687bb414b86a7ba109e0d8fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15342e7b0fba49a6bec8159a3ce5bee0",
              "IPY_MODEL_078d8bf24c0c4177b22515fc7f711be1",
              "IPY_MODEL_53b93dcbedea44949c31b30d57dbbab4"
            ],
            "layout": "IPY_MODEL_05ec16ec36d448e2886902a86adae18c"
          }
        },
        "15342e7b0fba49a6bec8159a3ce5bee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a63b629bff494ea1e2c7ed42eaa25c",
            "placeholder": "​",
            "style": "IPY_MODEL_85bb223e485d450c9d040613bfb194ff",
            "value": "merges.txt: 100%"
          }
        },
        "078d8bf24c0c4177b22515fc7f711be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe7a35b355f41b381a421aae2674028",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8399c6694c21493ca7af759bc5cfefcb",
            "value": 456318
          }
        },
        "53b93dcbedea44949c31b30d57dbbab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd31cff2cca44c4a8d5a56d9b8b7d0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0538f282ea46078775c8f53c1be249",
            "value": " 456k/456k [00:00&lt;00:00, 2.34MB/s]"
          }
        },
        "05ec16ec36d448e2886902a86adae18c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a63b629bff494ea1e2c7ed42eaa25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bb223e485d450c9d040613bfb194ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe7a35b355f41b381a421aae2674028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8399c6694c21493ca7af759bc5cfefcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd31cff2cca44c4a8d5a56d9b8b7d0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0538f282ea46078775c8f53c1be249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f1cbdcc8fc45399475074a51c1aec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2116903aef824ed2a7c50845a5d836c9",
              "IPY_MODEL_8f9e74e057404d2881c11542038b312e",
              "IPY_MODEL_7bafa551946d4cffa93c6fe7373a949d"
            ],
            "layout": "IPY_MODEL_57ba4c2cf4814da49a9e22fddb016786"
          }
        },
        "2116903aef824ed2a7c50845a5d836c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcab472b4d96474ebd3377960e01eca9",
            "placeholder": "​",
            "style": "IPY_MODEL_64d2ddd1b1ea4176aa3b36e2df2fe89a",
            "value": "tokenizer.json: 100%"
          }
        },
        "8f9e74e057404d2881c11542038b312e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_281cd597657d4c308ad4f5dd0b7cc428",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd080f5dc3124d6198c73d220ac26562",
            "value": 1355256
          }
        },
        "7bafa551946d4cffa93c6fe7373a949d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79255ed01bfe4879b3c93a69e66bb5bc",
            "placeholder": "​",
            "style": "IPY_MODEL_88fa2fc373e74476b2539dcec4de062a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.1MB/s]"
          }
        },
        "57ba4c2cf4814da49a9e22fddb016786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcab472b4d96474ebd3377960e01eca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d2ddd1b1ea4176aa3b36e2df2fe89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "281cd597657d4c308ad4f5dd0b7cc428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd080f5dc3124d6198c73d220ac26562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79255ed01bfe4879b3c93a69e66bb5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88fa2fc373e74476b2539dcec4de062a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Notebook : Used for model Training and Evaluation"
      ],
      "metadata": {
        "id": "qMq8qyvkVNW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 : Training the GPT2LM Model Using the Tokenized data file\n",
        " tokenized_single_turn_conversations_with_masks.pt"
      ],
      "metadata": {
        "id": "T21lDm70Tald"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zo6TtPGc6_7",
        "outputId": "1c77a290-26c9-4477-fdec-5ed070d8038e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# file path in Google Drive\n",
        "file_path = '/content/drive/MyDrive/Entropy/tokenized_conversations_with_context.pt'\n",
        "\n",
        "# Load the tokenized data with attention masks\n",
        "data = torch.load(file_path)\n",
        "input_ids = data['input_ids']\n",
        "attention_masks = data['attention_masks']\n",
        "\n",
        "print(\"Loaded input_ids and attention_masks:\")\n",
        "print(f\"Input IDs shape: {input_ids.shape}\")\n",
        "print(f\"Attention Masks shape: {attention_masks.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkDotpMEzEcg",
        "outputId": "5970edf2-0615-4341-d4e5-9db6074660c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-91864ec0757a>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded input_ids and attention_masks:\n",
            "Input IDs shape: torch.Size([83097, 512])\n",
            "Attention Masks shape: torch.Size([83097, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUpV2S7jdvAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# Load pre-trained GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Move loaded tokenized data to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_masks = attention_masks.to(device)\n",
        "\n",
        "print(\"Tokenized data and attention masks successfully moved to GPU.\")\n",
        "print(\"Model and data are ready on GPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TyyL236fcrm",
        "outputId": "76811de7-9650-4cb1-a6a3-7561ea7a0ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized data and attention masks successfully moved to GPU.\n",
            "Model and data are ready on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Design And Training"
      ],
      "metadata": {
        "id": "D396eafWTSKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# Assuming `input_ids`, `attention_masks`, and `model` are already loaded on the GPU\n",
        "\n",
        "# Step 3: Create a custom Dataset class and DataLoader\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_masks[idx]\n",
        "\n",
        "batch_size = 8  # Adjust based on GPU capacity\n",
        "train_dataset = ConversationDataset(input_ids, attention_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Step 4: Define optimizer and scaler for mixed precision training\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Function to save the model, optimizer, and scaler state\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, path):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"Checkpoint saved after epoch {epoch} to {path}\")\n",
        "\n",
        "# Step 5: Training loop with model, optimizer, and scaler saving after each epoch\n",
        "epochs = 2  # Modify as needed\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for input_ids_batch, attention_masks_batch in progress_bar:\n",
        "        input_ids_batch, attention_masks_batch = input_ids_batch.to(device), attention_masks_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(input_ids=input_ids_batch, attention_mask=attention_masks_batch, labels=input_ids_batch)\n",
        "            loss = outputs.loss\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed. Average loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "    # Save the model, optimizer, and scaler states after each epoch\n",
        "    checkpoint_path = f'/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_{epoch + 1}.pt'\n",
        "    save_checkpoint(epoch + 1, model, optimizer, scaler, checkpoint_path)\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "59By_M0f4z6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00573d68-c4e9-423f-b9bb-2a6ae8d9b2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ec6072da57cc>:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/10388 [00:00<?, ?it/s]<ipython-input-4-ec6072da57cc>:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed. Average loss: 0.44973561635207204\n",
            "Checkpoint saved after epoch 1 to /content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_1.pt\n",
            "Epoch 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 1301/10388 [09:31<1:07:02,  2.26it/s, loss=0.404]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 2 training from checkpoint 1"
      ],
      "metadata": {
        "id": "k1Ib3cGr-mzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the paths\n",
        "checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_1.pt'\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "# Load optimizer and scaler\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scaler = torch.amp.GradScaler()\n",
        "scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "print(\"Optimizer and scaler states loaded.\")\n",
        "\n",
        "# Assuming `input_ids` and `attention_masks` are already loaded on the GPU\n",
        "\n",
        "# Custom Dataset and DataLoader\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_masks[idx]\n",
        "\n",
        "batch_size = 8\n",
        "train_dataset = ConversationDataset(input_ids, attention_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Function to save the checkpoint\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, path):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"Checkpoint saved after epoch {epoch} to {path}\")\n",
        "\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "# Training loop for one additional epoch\n",
        "epochs = 1  # Continuing for one more epoch\n",
        "for epoch in range(epochs):\n",
        "    current_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"Continuing training: Epoch {current_epoch}\")\n",
        "    epoch_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for input_ids_batch, attention_masks_batch in progress_bar:\n",
        "        input_ids_batch, attention_masks_batch = input_ids_batch.to('cuda'), attention_masks_batch.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision training\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = model(input_ids=input_ids_batch, attention_mask=attention_masks_batch, labels=input_ids_batch)\n",
        "            loss = outputs.loss\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    print(f\"Epoch {current_epoch} completed. Average loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "    # Save the model, optimizer, and scaler states after the epoch\n",
        "    checkpoint_path = f'/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_{current_epoch}.pt'\n",
        "    save_checkpoint(current_epoch, model, optimizer, scaler, checkpoint_path)\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjML-hH0-iLx",
        "outputId": "54483f23-83b6-405c-a403-f390eebc2eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b1eb2ee36954>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer and scaler states loaded.\n",
            "Continuing training: Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed. Average loss: 0.4390451854634937\n",
            "Checkpoint saved after epoch 2 to /content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFsvjXWDIhNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following attempt got interrupted with a runtime end"
      ],
      "metadata": {
        "id": "VN2g59mTUlEV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfIFvusN2Ate",
        "outputId": "4d8be5f5-3142-4581-9bab-9f636030a1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3536c0610e1a>:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/19028 [00:00<?, ?it/s]<ipython-input-4-3536c0610e1a>:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training:  47%|████▋     | 8984/19028 [1:01:59<1:09:02,  2.42it/s, loss=0.371]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save the trained model after optimization\n",
        "token_save_path=f'/content/drive/MyDrive/Entropy/optimized_tokenizer'\n",
        "tokenizer.save_pretrained(token_save_path)\n",
        "\n",
        "print(\"tokenizer saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F_qtl4xgzYI",
        "outputId": "d6fd03c8-a61e-49ab-a362-ac103bcb53ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the trained model and tokenizer to Google Drive\n",
        "\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/optimized_tokenizer')"
      ],
      "metadata": {
        "id": "aadcDBMhjAyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3 : Evaluation"
      ],
      "metadata": {
        "id": "LRNvlO94HFpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model and the checkpoint\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt'\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Function to generate chatbot responses with attention mask\n",
        "def generate_response(prompt_text, model, tokenizer, max_length=150, num_return_sequences=1):\n",
        "    # Tokenize the input prompt with padding and attention mask\n",
        "    inputs = tokenizer(prompt_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Pass both input_ids and attention_mask to the model\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Generate responses\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Pass the attention mask to the model\n",
        "        max_length=max_length,  # Adjust maximum length of generated text\n",
        "        num_return_sequences=num_return_sequences,  # Generate one or more responses\n",
        "        no_repeat_ngram_size=2,  # Avoid repeating the same n-grams\n",
        "        do_sample=True,  # Enable sampling for varied responses\n",
        "        top_k=50,  # Sample from top k tokens\n",
        "        top_p=0.95,  # Use nucleus sampling (top-p sampling)\n",
        "        temperature=0.7,  # Lower temperature makes output more deterministic\n",
        "        pad_token_id=tokenizer.eos_token_id  # Set the pad token to eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated text\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Test the chatbot with a user input prompt\n",
        "prompt = \"Hello, how are you?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(f\"Chatbot response: {response}\")\n",
        "\n",
        "# Try another prompt\n",
        "prompt = \"Can you tell me a joke?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(f\"Chatbot response: {response}\")\n",
        "\n",
        "# Try another prompt\n",
        "prompt = \"do you like movies?\"\n",
        "response = generate_response(prompt, model, tokenizer)\n",
        "print(f\"Chatbot response: {response}\")\n"
      ],
      "metadata": {
        "id": "pA2pRh6LGJ_1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "e3d0f602cfb149ca9371e8da05f0b575",
            "d5200eab96ba4bc1abbee8fc8fe6e41a",
            "97a26df8bbc9493bad5493434ad95fc1",
            "463ea8267dc248a388d10bff53ef6091",
            "3d2813acacd945338454b0ce7413eb66",
            "31c98616c2024eef8fc525c59eae52d2",
            "d9658b6cc4984f80ab87e6dbf6a58ba7",
            "70c1fdafaa9b48929a2089850ecabbd8",
            "adb3930a53fa4e1094f391e7e120c419",
            "779086cd725b47f88b3c7f093aa018eb",
            "285e9e86ddfd467cb75b2d5da1ae0939",
            "d05da51637e947778763cb090f12f5db",
            "b3e62fc151b9407bb16242978444000f",
            "a7a3bc0e8f1044d9b623ab57d6c3d540",
            "39a645621f724678ae21f6ca50dd672a",
            "de0fb162ddad4f6a97510aba566e396a",
            "da2f5d3682b14fb78775b886348e55ac",
            "fd7eacd3397942fe9993822b132b0b9f",
            "dfdf5e35b6154746bee61bef8ada54b8",
            "6576c136152949ddae069012c9d036a4",
            "b9006243d0be453287cc868a4d328a62",
            "2421b4256d2f44be8cf84a2a2a9a72e6",
            "11b3f3c528f14a1fba59e9f56f90abd9",
            "2c18420c62414f74aecf68f6eb62300a",
            "d25960d2cc4740a18b1571cf4d024d15",
            "8827e0677a6b4705b5552ff72e972e48",
            "62735853e974416d9bb2a03e5e51450c",
            "930c7a1ede1d43518fe4547ae87c3078",
            "966fb7a7a79e435ab489d17865532089",
            "84eb662fecce489886127f702d5f6797",
            "324d0e84441a4d8189b6bbaf42162bc9",
            "a517b4e23c694d0381bfc5e840f46f2e",
            "e041277b88b7460da6d28e98e88b3c30",
            "86fca984b5aa4f7ea77779a213d217fa",
            "7d089679d42d4065afd9239bf6d0fc93",
            "34d834ed555d4426a19821f233a4568f",
            "e669169671cf49c88c8984c043fca802",
            "3b344ae6a1d84f0abffc91d15f20a160",
            "4ef39fcb95bf453c902be5f4a27b0149",
            "b2e6f05a980749fcaf6afcbcadd4825a",
            "2c1596f02aa24c3bb2e6a5fb9443a159",
            "2d81104bf744403c90ad4afd405683a9",
            "8aadad6980664f10830730ae2c9dd5ff",
            "031bab7d8a394481b8dfbb4413ec5ab6",
            "3b5b375faba742f788e00d7ce47babda",
            "2e098f5b42b84cb98cc87fb0d566aa4c",
            "4bf624f2b2cf4d73be47ca254c2541f5",
            "4667a244280e4623bb878c86c61be2d0",
            "5fb22f3ee16b4bd1b85f0753fd9c0546",
            "0d04158c6aed40c28b106c80dfed8cc4",
            "15336168581a4bdb99b066f9186aee71",
            "3bb51332c174405289decaac73961ec5",
            "c7be4c3bc62347b3ab19a82bdd4cf34f",
            "acb4e388837f49bb964b9b2dc6321357",
            "dffd8b755824412faf16bcf471eacfb2",
            "0f471af687bb414b86a7ba109e0d8fa2",
            "15342e7b0fba49a6bec8159a3ce5bee0",
            "078d8bf24c0c4177b22515fc7f711be1",
            "53b93dcbedea44949c31b30d57dbbab4",
            "05ec16ec36d448e2886902a86adae18c",
            "e9a63b629bff494ea1e2c7ed42eaa25c",
            "85bb223e485d450c9d040613bfb194ff",
            "cbe7a35b355f41b381a421aae2674028",
            "8399c6694c21493ca7af759bc5cfefcb",
            "fd31cff2cca44c4a8d5a56d9b8b7d0bb",
            "aa0538f282ea46078775c8f53c1be249",
            "c4f1cbdcc8fc45399475074a51c1aec0",
            "2116903aef824ed2a7c50845a5d836c9",
            "8f9e74e057404d2881c11542038b312e",
            "7bafa551946d4cffa93c6fe7373a949d",
            "57ba4c2cf4814da49a9e22fddb016786",
            "fcab472b4d96474ebd3377960e01eca9",
            "64d2ddd1b1ea4176aa3b36e2df2fe89a",
            "281cd597657d4c308ad4f5dd0b7cc428",
            "cd080f5dc3124d6198c73d220ac26562",
            "79255ed01bfe4879b3c93a69e66bb5bc",
            "88fa2fc373e74476b2539dcec4de062a"
          ]
        },
        "outputId": "e09a841b-667d-4d02-a06d-af4aa178c4fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3d0f602cfb149ca9371e8da05f0b575"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d05da51637e947778763cb090f12f5db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11b3f3c528f14a1fba59e9f56f90abd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-88a5275692f0>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86fca984b5aa4f7ea77779a213d217fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b5b375faba742f788e00d7ce47babda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f471af687bb414b86a7ba109e0d8fa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4f1cbdcc8fc45399475074a51c1aec0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot response: Hello, how are you?\n",
            "\n",
            "How are things?  Do you like to play hockey? Do ya like it? You like the game? Come on, come on.\n",
            "Oh, I know I should say this but I really don't know.  I'm just not ready to go out. I dont know whatI donít wanna go anywhere. Don¹t go to the airport. Its going to be a long, long time. You never know when youre gonna get there. What is the worst thing that could happen? The worst would be that you're not gonna go. Like I said, its gonna be pretty bad. But I'll get\n",
            "Chatbot response: Can you tell me a joke?\n",
            "\n",
            "<GUILD (male)\n",
            "\n",
            "Chatbot response: do you like movies?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mvu9fxKXeXB",
        "outputId": "7f8935ef-5c90-4688-f2b9-3e455d888aeb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model and the checkpoint\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt'\n",
        "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Function to generate chatbot responses with attention mask\n",
        "def generate_response(prompt_text, model, tokenizer, max_new_tokens=100):\n",
        "    inputs = tokenizer(prompt_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Generate the response\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=max_new_tokens,  # Limit the number of new tokens generated\n",
        "        no_repeat_ngram_size=2,\n",
        "        repetition_penalty=1.2,  # Discourage repetitive sequences\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated text\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Interactive conversation loop\n",
        "print(\"Chatbot is ready! Type 'exit' to end the conversation.\")\n",
        "conversation_history = \"\"\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input()  # Removed \"You: \" prompt for a more natural texting experience\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Ending the conversation. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Append the user input to the conversation history\n",
        "    conversation_history += f\"\\n{user_input}\"\n",
        "\n",
        "    # Limit conversation history to the most recent exchanges\n",
        "    conversation_history_list = conversation_history.split(\"\\n\")\n",
        "    recent_history = \"\\n\".join(conversation_history_list[-6:])  # Last 3 exchanges (user + bot)\n",
        "    prompt_text = recent_history\n",
        "\n",
        "    # Generate chatbot response\n",
        "    chatbot_response = generate_response(prompt_text, model, tokenizer)\n",
        "    conversation_history += f\"\\n{chatbot_response}\"\n",
        "\n",
        "    # Print chatbot response\n",
        "    print(chatbot_response)\n",
        "\n",
        "    # Logging conversation for later evaluation\n",
        "    with open(\"conversation_log.txt\", \"a\") as log_file:\n",
        "        log_file.write(f\"{user_input}\\n{chatbot_response}\\n\\n\")\n",
        "\n",
        "    # Collect user feedback on the response\n",
        "    feedback = input(\"Rate the bot's response (1-5): \")\n",
        "    with open(\"feedback_log.txt\", \"a\") as feedback_file:\n",
        "        feedback_file.write(f\"{user_input} -> {chatbot_response}: Rating: {feedback}\\n\")"
      ],
      "metadata": {
        "id": "SmQuDqv-GMlr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e4b50dc-de5d-4c5d-ec5f-47a6b5a9ec5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' to end the conversation.\n",
            "Good Morning, How are you doing today ?\n",
            "\n",
            "Good Morning, How are you doing today? Are there any changes in your day-tomovie? Or is that something else?\n",
            "<good morning. I'm gonna be late tonight and go to work.  You know this will be a long ride, but hey! Come on for the ride! Just wait till I get home from my job tomorrow night...I'll have it all figured out by the time we're back at the airport -- just be patient with me here until then -\n",
            "\n",
            "Rate the bot's response (1-5): 2\n",
            "lets head out for lunch today, what cuisine to do like ?\n",
            "Good Morning, How are you doing today?\n",
            "\n",
            "Good Morning, How are you doing today? Are there any changes in your day-tomovie? Or is that something else?\n",
            "<good morning. I'm gonna be late tonight and go to work.  You know this will be a long ride, but hey! Come on for the ride! Just wait till I get home from my job tomorrow night...I'll have it all figured out by the time we're back at the airport -- just be patient with me here until then -\n",
            "\n",
            "lets head out for lunch today, what cuisine to do like? Do they have salads or dalas?  We might want some pizza when our flight arrives in London. It's great! Let us eat. My husband and his wife have a nice little place down at Pintrest..\n",
            "\n",
            "Rate the bot's response (1-5): 3\n",
            "exit.\n",
            "Good Morning, How are you doing today? Are there any changes in your day-tomovie? Or is that something else?\n",
            "<good morning. I'm gonna be late tonight and go to work.  You know this will be a long ride, but hey! Come on for the ride! Just wait till I get home from my job tomorrow night...I'll have it all figured out by the time we're back at the airport -- just be patient with me here until then -\n",
            "\n",
            "lets head out for lunch today, what cuisine to do like? Do they have salads or dalas?  We might want some pizza when our flight arrives in London. It's great! Let us eat. My husband and his wife have a nice little place down at Pintrest..\n",
            "\n",
            "exit.\n",
            "Rate the bot's response (1-5): 1\n",
            "1\n",
            "<good morning. I'm gonna be late tonight and go to work.  You know this will be a long ride, but hey! Come on for the ride! Just wait till I get home from my job tomorrow night...I'll have it all figured out by the time we're back at the airport -- just be patient with me here until then -\n",
            "\n",
            "lets head out for lunch today, what cuisine to do like? Do they have salads or dalas?  We might want some pizza when our flight arrives in London. It's great! Let us eat. My husband and his wife have a nice little place down at Pintrest..\n",
            "\n",
            "exit.\n",
            "1) Get off of there immediately before you leave town right now: that means no more trouble at all in between your jobs afternoon meetings-- and make sure he doesn't have any trouble getting to bed, okay?! And don't worry about your day-job if things keep going well enough. No one ever asks you where exactly everything is going so why bother? That way nobody has doubts about anything either; not even himself anymore than he is now anyway....You think your life would be better if\n",
            "Rate the bot's response (1-5): exit.\n",
            "1\n",
            "\n",
            "lets head out for lunch today, what cuisine to do like? Do they have salads or dalas?  We might want some pizza when our flight arrives in London. It's great! Let us eat. My husband and his wife have a nice little place down at Pintrest..\n",
            "\n",
            "exit.\n",
            "1) Get off of there immediately before you leave town right now: that means no more trouble at all in between your jobs afternoon meetings-- and make sure he doesn't have any trouble getting to bed, okay?! And don't worry about your day-job if things keep going well enough. No one ever asks you where exactly everything is going so why bother? That way nobody has doubts about anything either; not even himself anymore than he is now anyway....You think your life would be better if\n",
            "1a>you were away from home... <u></u>. Then we could go out together without worrying about the people around him with their own lives being fucked up by everyone else.' I thought maybe my whole life was just going on as I went along until it got too late 'cause I'd always be hungry for something but then all those years had gone into making that dream come true'.....then suddenly after all these years -- this love...the world and its people are such an awesome lot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-838eb2c21ced>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Collect user feedback on the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate the bot's response (1-5): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feedback_log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeedback_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mfeedback_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{user_input} -> {chatbot_response}: Rating: {feedback}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model and the checkpoint\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt'\n",
        "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Function to generate chatbot responses with attention mask\n",
        "def generate_response(prompt_text, model, tokenizer, max_new_tokens=1000):\n",
        "    if prompt_text.lower() == 'exit':\n",
        "        return \"Ending the conversation. Goodbye!\"\n",
        "\n",
        "    inputs = tokenizer(prompt_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Generate the response\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=max_new_tokens,  # Limit the number of new tokens generated\n",
        "        no_repeat_ngram_size=2,\n",
        "        repetition_penalty=1.2,  # Discourage repetitive sequences\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated text\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Interactive conversation loop\n",
        "print(\"Chatbot is ready! Type 'exit' to end the conversation.\")\n",
        "conversation_history = \"\"\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input()  # Removed \"You: \" prompt for a more natural texting experience\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Ending the conversation. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Append the user input to the conversation history\n",
        "    conversation_history += f\"\\n{user_input}\"\n",
        "\n",
        "    # Limit conversation history to the most recent exchanges\n",
        "    conversation_history_list = conversation_history.split(\"\\n\")\n",
        "    recent_history = \"\\n\".join(conversation_history_list[-6:])  # Last 3 exchanges (user + bot)\n",
        "    prompt_text = recent_history\n",
        "\n",
        "    # Generate chatbot response\n",
        "    chatbot_response = generate_response(prompt_text, model, tokenizer)\n",
        "    conversation_history += f\"\\n{chatbot_response}\"\n",
        "\n",
        "    # Print chatbot response\n",
        "    print(chatbot_response)\n",
        "\n",
        "    # Logging conversation for later evaluation\n",
        "    if user_input.lower() != 'exit':\n",
        "        with open(\"conversation_log.txt\", \"a\") as log_file:\n",
        "            log_file.write(f\"{user_input}\\n{chatbot_response}\\n\\n\")\n",
        "\n",
        "    # Collect user feedback on the response\n",
        "    if user_input.lower() != 'exit':\n",
        "        feedback = input(\"Rate the bot's response (1-5): \")\n",
        "        with open(\"feedback_log.txt\", \"a\") as feedback_file:\n",
        "            feedback_file.write(f\"{user_input} -> {chatbot_response}: Rating: {feedback}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuKIk-QXcfvc",
        "outputId": "b98e4f0c-ff7f-48c5-b626-01fad85e8e3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' to end the conversation.\n",
            "Bounjor how are you ?\n",
            "\n",
            "Bounjor how are you?  I'm very glad you're here. We've been able to work together for a long time, but we haven't done anything really special. Not even the best of things. For instance: maybe we should buy some clothes. And maybe our father would like us something nice and clean.\n",
            "\n",
            "Rate the bot's response (1-5): 5\n",
            "do you like movies ?\n",
            "\n",
            "Bounjor how are you?\n",
            "\n",
            "Bounjor how are you?  I'm very glad you're here. We've been able to work together for a long time, but we haven't done anything really special. Not even the best of things. For instance: maybe we should buy some clothes. And maybe our father would like us something nice and clean.\n",
            "\n",
            "do you like movies? Do not tell anyone about them! But why do they always have this picture in their back pocket that says \"You're a great writer\" or whatever it is they think 'n' wanna hear your name be on TV!\n",
            "you can write songs? A song about me?! Or do what my mother tells ya...\n",
            "what's wrong with lovemaking right now??? It has nothing else left from childhood?\n",
            "maybe there was never any chance at all before when she married him...? Maybe someday he'll find out.....I dont know....he did look up every word!!! How do these girls know everything!?\n",
            "just because someone likes her doesn then they will get along well enough!!\n",
            "Rate the bot's response (1-5): 4\n",
            "lets go for lunch and then head out for a movie .. what do you say ?\n",
            "do you like movies? Do not tell anyone about them! But why do they always have this picture in their back pocket that says \"You're a great writer\" or whatever it is they think 'n' wanna hear your name be on TV!\n",
            "you can write songs? A song about me?! Or do what my mother tells ya...\n",
            "what's wrong with lovemaking right now??? It has nothing else left from childhood?\n",
            "maybe there was never any chance at all before when she married him...? Maybe someday he'll find out.....I dont know....he did look up every word!!! How do these girls know everything!?\n",
            "just because someone likes her doesn then they will get along well enough!!\n",
            "lets go for lunch and then head out for a movie.. what do you say?  Oh, God I wish we could go on the road together. We are so much alike here..\n",
            "\n",
            "Rate the bot's response (1-5): 5\n",
            "exit\n",
            "Ending the conversation. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import time\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model and the checkpoint\n",
        "try:\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt'\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "\n",
        "# Load the tokenizer\n",
        "try:\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "\n",
        "# Function to generate chatbot responses with attention mask\n",
        "def generate_response(prompt_text, model, tokenizer, max_new_tokens=1000):\n",
        "    if prompt_text.lower() == 'exit':\n",
        "        return \"Ending the conversation. Goodbye!\"\n",
        "\n",
        "    try:\n",
        "        inputs = tokenizer(prompt_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        # Generate the response\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=max_new_tokens,  # Limit the number of new tokens generated\n",
        "            no_repeat_ngram_size=2,\n",
        "            repetition_penalty=1.2,  # Discourage repetitive sequences\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # Decode and return the generated text\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"Sorry, I encountered an error while generating a response.\"\n",
        "\n",
        "# Interactive conversation loop with enhanced logging and memory management\n",
        "print(\"Chatbot is ready! Type 'exit' to end the conversation.\")\n",
        "conversation_history = \"\"\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input()\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Ending the conversation. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Append the user input to the conversation history\n",
        "    conversation_history += f\"\\n{user_input}\"\n",
        "\n",
        "    # Limit conversation history to the most recent exchanges (sliding window of last 6 lines)\n",
        "    conversation_history_list = conversation_history.split(\"\\n\")\n",
        "    recent_history = \"\\n\".join(conversation_history_list[-6:])  # Last 3 exchanges (user + bot)\n",
        "    prompt_text = recent_history\n",
        "\n",
        "    # Generate chatbot response\n",
        "    chatbot_response = generate_response(prompt_text, model, tokenizer)\n",
        "    conversation_history += f\"\\n{chatbot_response}\"\n",
        "\n",
        "    # Print chatbot response\n",
        "    print(chatbot_response)\n",
        "\n",
        "    # Unified logging of conversation and feedback with timestamps\n",
        "    if user_input.lower() != 'exit':\n",
        "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        log_entry = f\"{timestamp} | User: {user_input} | Bot: {chatbot_response}\\n\"\n",
        "\n",
        "        # Write to a single log file for both conversation and feedback\n",
        "        with open(\"conversation_and_feedback_log.txt\", \"a\") as log_file:\n",
        "            log_file.write(log_entry)\n",
        "\n",
        "        # Collect user feedback on the response\n",
        "        feedback = input(\"Rate the bot's response (1-5): \")\n",
        "        with open(\"conversation_and_feedback_log.txt\", \"a\") as log_file:\n",
        "            log_file.write(f\"Rating: {feedback}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tF3xZnDfPT8",
        "outputId": "ad7eeb68-efcf-4549-8ff3-90098fccf3ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Chatbot is ready! Type 'exit' to end the conversation.\n",
            "Good Morning \n",
            "\n",
            "Good Morning  Good Evening. Just what I needed...\n",
            "\n",
            "Rate the bot's response (1-5): 5\n",
            "how are you doing today ?\n",
            "\n",
            "Good Morning \n",
            "\n",
            "Good Morning  Good Evening. Just what I needed...\n",
            "\n",
            "how are you doing today? Are your hands warm? Do they feel good right now, or is there something wrong with them...? Is it too late to come in here...?\n",
            "\n",
            "Rate the bot's response (1-5): no its not too late, come on in please \n",
            "5\n",
            "\n",
            "Good Morning  Good Evening. Just what I needed...\n",
            "\n",
            "how are you doing today? Are your hands warm? Do they feel good right now, or is there something wrong with them...? Is it too late to come in here...?\n",
            "\n",
            "5:30-6PM - How about tonight?! What do we have left for the next few hours?? Come and see me at my place! We'll talk tomorrow night as best he can!! Don't worry though; if anything goes awry--I'm fine after all this work that's already done on him so don't even bother to tell anyone... My family will be happy knowing everybody's safe and sound again soon enough.... Happy everyone wants us back together.. So please, stay here while everything works out alright before dawn.....and keep a watchful eye when things get dark around our house which means every night.\n",
            "7 PM THE END OF DAY AND NIGHT MONDAYS IN A HARDY CIRCLE.\n",
            "Rate the bot's response (1-5): 5\n",
            "exit\n",
            "Ending the conversation. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2gP8Umg22ntO",
        "outputId": "e552dc42-cbf9-421f-8a6b-43115703c271"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio)\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.0-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.40.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, markupsafe, h11, ffmpy, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.1\n",
            "    Uninstalling MarkupSafe-3.0.1:\n",
            "      Successfully uninstalled MarkupSafe-3.0.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.2 ffmpy-0.4.0 gradio-5.1.0 gradio-client-1.4.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.0 markupsafe-2.1.5 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.0 semantic-version-2.10.0 starlette-0.40.0 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "50e4b5db96924392a4d2fe58e0e8c044"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import time\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained model and the checkpoint\n",
        "try:\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    checkpoint_path = '/content/drive/MyDrive/Entropy/gpt2_finetuned_checkpoint_epoch_2.pt'\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "\n",
        "# Load the tokenizer\n",
        "try:\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "\n",
        "# Function to generate chatbot responses with attention mask\n",
        "def generate_response_gradio(user_input, conversation_history):\n",
        "    try:\n",
        "        # Update the conversation history\n",
        "        conversation_history.append((\"User\", user_input))\n",
        "\n",
        "        # Limit conversation history to the most recent exchanges (sliding window of last 6 lines)\n",
        "        conversation_history_list = [f\"{speaker}: {text}\" for speaker, text in conversation_history[-6:]]  # Last 3 exchanges (user + bot)\n",
        "        prompt_text = \"\\n\".join(conversation_history_list)\n",
        "\n",
        "        # Tokenize and generate the response\n",
        "        inputs = tokenizer(prompt_text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=1000,  # Limit the number of new tokens generated\n",
        "            no_repeat_ngram_size=2,\n",
        "            repetition_penalty=1.2,  # Discourage repetitive sequences\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # Decode and return the generated text\n",
        "        chatbot_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Update the conversation history with the chatbot response\n",
        "        conversation_history.append((\"Bot\", chatbot_response))\n",
        "        return conversation_history\n",
        "\n",
        "    except Exception as e:\n",
        "        conversation_history.append((\"Bot\", \"Sorry, I encountered an error while generating a response.\"))\n",
        "        return conversation_history\n",
        "\n",
        "# Gradio Interface\n",
        "def chat_interface(user_input, conversation_history=[]):\n",
        "    updated_history = generate_response_gradio(user_input, conversation_history)\n",
        "    return updated_history, updated_history\n",
        "\n",
        "# Gradio Input/Output elements\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### GPT-2 Chatbot\")\n",
        "    chatbot = gr.Chatbot()  # Chatbot display for back-and-forth conversation\n",
        "    chatbot_history = gr.State([])  # Hidden state to store conversation history\n",
        "    user_input = gr.Textbox(label=\"Your Input\")\n",
        "\n",
        "    def chat_with_bot(input_text, chat_history):\n",
        "        response, new_history = chat_interface(input_text, chat_history)\n",
        "        return new_history, new_history\n",
        "\n",
        "    user_input.submit(chat_with_bot, inputs=[user_input, chatbot_history], outputs=[chatbot, chatbot_history])\n",
        "\n",
        "# Launch Gradio interface\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "GmfGLqL53POm",
        "outputId": "bc88f38a-324f-4504-9409-b803c038a0b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d85155495634b8a62b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d85155495634b8a62b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab import drive, files\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import nbformat\n",
        "from nbconvert import HTMLExporter\n",
        "import uuid\n",
        "import subprocess\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def get_most_recent_ipynb(path):\n",
        "    notebooks = glob.glob(os.path.join(path, '*.ipynb'))\n",
        "    if not notebooks:\n",
        "        return None\n",
        "    most_recent_file = max(notebooks, key=os.path.getmtime)\n",
        "    return most_recent_file\n",
        "\n",
        "def export_notebook_as_html(notebook_path, checkpoint_name='', export_path='/content/html_exports'):\n",
        "    with open(notebook_path, 'r') as f:\n",
        "        notebook_content = nbformat.read(f, as_version=4)\n",
        "\n",
        "    html_exporter = HTMLExporter()\n",
        "    html_content, _ = html_exporter.from_notebook_node(notebook_content)\n",
        "\n",
        "    base_name = os.path.splitext(notebook_path)[0]\n",
        "    html_output_path = os.path.join(export_path, f\"{os.path.basename(base_name)}{checkpoint_name}_{uuid.uuid4().hex[:4]}.html\")\n",
        "\n",
        "    os.makedirs(export_path, exist_ok=True)  # Create directory if it doesn't exist\n",
        "\n",
        "    with open(html_output_path, 'w') as f:\n",
        "        f.write(html_content)\n",
        "    files.download(html_output_path)\n",
        "\n",
        "def download(checkpoint_name=\"\"):\n",
        "  if checkpoint_name and not checkpoint_name.startswith('_') and not checkpoint_name.startswith('-'):\n",
        "    checkpoint_name = '_' + checkpoint_name\n",
        "  recent_ipynb = get_most_recent_ipynb('/content/drive/My Drive/Colab Notebooks/')\n",
        "  if recent_ipynb:\n",
        "      export_notebook_as_html(recent_ipynb, checkpoint_name)\n",
        "\n",
        "download(\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "RnXEqtkfUtPa",
        "outputId": "2ba34557-d575-4b98-8e4a-1863e70f6acc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/widgetsdatatypefilter.py:71: UserWarning: Your element with mimetype(s) dict_keys(['application/vnd.colab-display-data+json']) is not able to be represented.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c1b6002-1e79-4c99-9990-76d49c833160\", \"15102024_EntropyV2_Colab_test_629c.html\", 786042)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}